---
title: "Ideas for final project"
format: html
---

*Note:* I will continue to update this list as we go. If more than 3 groups propose the same project, I will ask you to coordinate to make sure your projects are different enough from one another. 

# Potential Topics 

1. Proof of Invariance of MLE
2. Expectation-Maximization (E-M) algorithm 
3. Gibb's Sampling
4. Jeffrey's Prior 
5. Prove Cramer-Rao 
6. Zero-Inflated Poisson Distribution
7. Cauchy distribution 
8. Conjugate Priors for Exponential Family
9. Confidence intervals for QQplots
10. Bayesian Estimation for $L_1$ loss function
11. Bayesian Highest Posterior Density Intervals 
12. There are a number of heuristics for when we can use large-sample approximations (e.g. using the normal distribution instead of the T distribution, using the normal distribution instead of the binomial distribution, etc.). Show why these heuristics came to be and explore if/when they fail. 
13. Choose a named distribution that we've worked with in class, and research the two-dimensional version of that distribution. This should include deriving the PDF, CDF, expected value, variance, MGF, etc.; how to do inference for the parameter(s); and an example of why the distribution is useful. 
14. Research and provide a proof for the *Neyman-Pearson* Lemma, which states that the GLRT is at least as powerful as any other test with the same or smaller $\alpha$. 
15. Research and provide a proof for *Wilks; Theorem*, which states that if $\lambda$ is the GLRT statistic, $-2 \ln \lambda$ is an approximate $\chi^2$ random variable. (Taylor expansion alert!!) 

You are also welcome to propose your own topic! I encourage you to talk with me before submitting a proposal to make sure that it is appropriate for the class. 

